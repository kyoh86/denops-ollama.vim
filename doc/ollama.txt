*ollama.txt* A Vim plugin as ...
                                                  *ollama* *denops-ollama.txt*

Author: kyoh86 <me@kyoh86.dev>
License: MIT License


==============================================================================
                                                             *ollama-contents*
Contents ~

Install						|ollama-install|
Setup						|ollama-setup|
Function					|ollama-function|
Commands					|ollama-commands|
Keymaps						|ollama-keymaps|
Denops commands	 				|ollama-denops-commands|
Other references				|ollama-references|


==============================================================================
                                                              *ollama-install*
Install ~

You need to install *denops.vim* as a dependency.

* vim-denops/denops.vim https://github.com/vim-denops/denops.vim
* ollama https://ollama.ai


==============================================================================
                                                                *ollama-setup*
Setup ~


==============================================================================
                                                             *ollama-function*
Function ~

                                                         *ollama#start_chat()*
ollama#start_chat({model} [, {opener}])
	Start chat with Ollama using the {model}.
	See |ollama-model-names|.

	{opener} specify how the new buffer be placed in which window:
		- "tabnew": (DEFAULT) open a new tab
		- "split", "new": open a new split
		- "vsplit", "vnew": open a new vertical split
		- "edit": open a new buffer in the current window

	Example: >
	:call ollama#start_chat('codellama', 'new')
<

                                            *ollama#start_chat_with_context()*
ollama#start_chat_with_context({model}, {context} [, {opener}])
	Start chat with Ollama with the context using the {model}.
	See |ollama-model-names|.

	{context} specifies what kind of context should be passed to Ollama
	in advance.
	It supports the following entries:
		- headMessage	A first message to be sent.
		- selection	If the selection be sent.
		- currentBuffer	If the current buffer be sent.
		- buffers	A list of the bufinfo.
		  		It accepts buffer numbers (see |bufnr()|) or
				the objects from |getbufinro()|.
		- lastMessage	A last message to be sent.

	{opener} specify how the new buffer be placed in which window:
		- "tabnew": (DEFAULT) open a new tab
		- "split", "new": open a new split
		- "vsplit", "vnew": open a new vertical split
		- "edit": open a new buffer in the current window

	Example: >
	:call ollama#start_chat_with_context('codellama', {
		\ "selection": v:true,
		\ "buffers:" [1, {"bufnr": 2, "name": "foo"}],
		\ }, 'tabnew')
	:call ollama#start_chat_with_context('codellama', {
		\ "selection": v:true,
		\ "buffers:" getbufinfo({"buflisted":v:true}),
		\ })
<

                                                        *ollama#list_models()*
ollama#list_models()
	Show list models in local.

	Example: >
	:call ollama#list_models()
<

                                                         *ollama#pull_model()*
ollama#pull_model({name} [, {insecure}])
	Pull a model by the {name} from the library.
	See |ollama-model-names|.

	If {insecure} is true, allow insecure connections to the library.

	Example: >
	:call ollama#pull_model('codellama')
<

                                                       *ollama#delete_model()*
ollama#delete_model({name})
	Delete a model by the {name} in local.
	See |ollama-model-names|.

	Example: >
	:call ollama#delete_model('codellama')
<

                                                             *ollama#cancel()*
ollama#cancel()
	Cancell all background jobs.

	Example: >
	:call ollama#cancel()
<


==============================================================================
                                                             *ollama-commands*
Commands ~


==============================================================================
                                                              *ollama-keymaps*
Keymaps ~


==============================================================================
                                                           *ollama-references*
Other references ~

                                                          *ollama-model-names*
Model names ~
https://github.com/jmorganca/ollama/blob/main/docs/api.md#model-names


==============================================================================
" vim:tw=78:ts=8:sw=8:ft=help:norl:noet:fen:
